{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_top\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/Pytochtop.png\" width=\"750\" alt=\"IBM Product \" />\n",
    "</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/cc-logo-square.png\" width=\"200\" alt=\"cognitiveclass.ai logo\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Torch Tensors in 1D</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Table of Contents</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In this lab, you will learn the basics of tensor operations. Tensors are an essential part of PyTorch; there are complex mathematical objects in and of themselves. Fortunately, most of the intricacies are not necessary. In this section, you will compare them to vectors and numpy arrays.</p>\n",
    "<ul>\n",
    "    <li><a href=\"#Types_Shape\">Types and Shape</a></li>\n",
    "    <li><a href=\"#Index_Slice\">Indexing and Slicing</a></li>\n",
    "    <li><a href=\"#Tensor_Func\">Tensor Functions</a></li>\n",
    "    <li><a href=\"#Tensor_Op\">Tensor Operations</a></li>\n",
    "    <li><a href=\"#Device_Op\">Device_Op Operations</a></li>\n",
    "</ul>\n",
    "\n",
    "<p>Estimated Time Needed: <b>25 min</b></p>\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Preparation</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Import the following libraries that you'll use for this lab:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# These are the libraries will be used for this lab.\n",
    "\n",
    "import torch \n",
    "import numpy as np \n",
    "import pandas as pd\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check PyTorch version:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'1.4.0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the function for plotting diagrams. You will use this function to plot the vectors in Coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot vecotrs, please keep the parameters in the same length\n",
    "# @param: Vectors = [{\"vector\": vector variable, \"name\": name of vector, \"color\": color of the vector on diagram}]\n",
    "    \n",
    "def plotVec(vectors):\n",
    "    ax = plt.axes()\n",
    "    \n",
    "    # For loop to draw the vectors\n",
    "    for vec in vectors:\n",
    "        ax.arrow(0, 0, *vec[\"vector\"], head_width = 0.05,color = vec[\"color\"], head_length = 0.1)\n",
    "        plt.text(*(vec[\"vector\"] + 0.1), vec[\"name\"])\n",
    "    \n",
    "    plt.ylim(-2,2)\n",
    "    plt.xlim(-2,2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Types_Shape\">Types and Shape</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the type of the following list of integers <i>[0, 1, 2, 3, 4]</i> by applying the constructor <code>torch.tensor()</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dtype of tensor object after converting it to tensor:  torch.int64\n",
      "The type of tensor object after converting it to tensor:  torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "# Convert a integer list with length 5 to a tensor\n",
    "\n",
    "ints_to_tensor = torch.tensor([0, 1, 2, 3, 4])\n",
    "print(\"The dtype of tensor object after converting it to tensor: \", ints_to_tensor.dtype)\n",
    "print(\"The type of tensor object after converting it to tensor: \", ints_to_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, the integer list has been converted to a long tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Python type is still <code>torch.Tensor</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Tensor"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(ints_to_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separate topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can find the type of this float list <i>[0.0, 1.0, 2.0, 3.0, 4.0]</i> by applying the method <code>torch.tensor()</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dtype of tensor object after converting it to tensor:  torch.float32\n",
      "The type of tensor object after converting it to tensor:  torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Convert a float list with length 5 to a tensor\n",
    "\n",
    "floats_to_tensor = torch.tensor([0.0, 1.0, 2.0, 3.0, 4.0])\n",
    "print(\"The dtype of tensor object after converting it to tensor: \", floats_to_tensor.dtype)\n",
    "print(\"The type of tensor object after converting it to tensor: \", floats_to_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The float list is converted to a float tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_floats=[0.0, 1.0, 2.0, 3.0, 4.0]\n",
    "\n",
    "floats_int_tensor=torch.tensor(list_floats,dtype=torch.int64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dtype of tensor object is:  torch.int64\n",
      "The type of tensor object is:  torch.LongTensor\n"
     ]
    }
   ],
   "source": [
    "print(\"The dtype of tensor object is: \", floats_int_tensor.dtype)\n",
    "print(\"The type of tensor object is: \", floats_int_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: The elements in the list that will be converted to tensor must have the same type.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the previous examples, you see that <code>torch.tensor()</code> converts the list to the tensor type, which is similar to the original list type. However, what if you want to convert the list to a certain tensor type? <code>torch</code> contains the methods required to do this conversion. The following code  converts an integer list to float tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of the new_float_tensor: torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Convert a integer list with length 5 to float tensor\n",
    "\n",
    "new_float_tensor = torch.FloatTensor([0, 1, 2, 3, 4])\n",
    "new_float_tensor.type()\n",
    "print(\"The type of the new_float_tensor:\", new_float_tensor.type())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_float_tensor = torch.FloatTensor([0, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert an existing tensor object (<code><i>tensor_obj</i></code>) to another tensor type. Convert the integer tensor to a float tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The type of the new_float_tensor: torch.FloatTensor\n"
     ]
    }
   ],
   "source": [
    "# Another method to convert the integer list to float tensor\n",
    "\n",
    "old_int_tensor = torch.tensor([0, 1, 2, 3, 4])\n",
    "new_float_tensor = old_int_tensor.type(torch.FloatTensor)\n",
    "print(\"The type of the new_float_tensor:\", new_float_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code><i>tensor_obj</i>.size()</code> helps you to find out the size of the <code><i>tensor_obj</i></code>.\n",
    "The <code><i>tensor_obj</i>.ndimension()</code> shows the dimension of the tensor object."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The size of the new_float_tensor:  torch.Size([5])\n",
      "The dimension of the new_float_tensor:  1\n"
     ]
    }
   ],
   "source": [
    "# Introduce the tensor_obj.size() & tensor_ndimension.size() methods\n",
    "\n",
    "print(\"The size of the new_float_tensor: \", new_float_tensor.size())\n",
    "print(\"The dimension of the new_float_tensor: \",new_float_tensor.ndimension())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The <code><i>tensor_obj</i>.view(<i>row, column</i>)</code> is used for reshaping a tensor object.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you have a tensor object with <code>torch.Size([5])</code> as a <code>new_float_tensor</code> as shown in the previous example?<br>\n",
    "After you execute <code>new_float_tensor.view(5, 1)</code>, the size of <code>new_float_tensor</code> will be <code>torch.Size([5, 1])</code>.<br>\n",
    "This means that the tensor object <code>new_float_tensor</code> has been reshaped from a one-dimensional  tensor object with 5 elements to a two-dimensional tensor object with 5 rows and 1 column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size:  tensor([0., 1., 2., 3., 4.])\n",
      "Size after view method tensor([[0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]])\n"
     ]
    }
   ],
   "source": [
    "# Introduce the tensor_obj.view(row, column) method\n",
    "\n",
    "twoD_float_tensor = new_float_tensor.view(5, 1)\n",
    "print(\"Original Size: \", new_float_tensor)\n",
    "print(\"Size after view method\", twoD_float_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the original size is 5. The tensor after reshaping becomes a 5X1 tensor analog to a column vector."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: The number of elements in a tensor must remain constant after applying view.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What if you have a tensor with dynamic size but you want to reshape it? You can use <b>-1</b> to do just that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original Size:  tensor([0., 1., 2., 3., 4.])\n",
      "Size after view method tensor([[0.],\n",
      "        [1.],\n",
      "        [2.],\n",
      "        [3.],\n",
      "        [4.]])\n"
     ]
    }
   ],
   "source": [
    "# Introduce the use of -1 in tensor_obj.view(row, column) method\n",
    "\n",
    "twoD_float_tensor = new_float_tensor.view(-1, 1)\n",
    "print(\"Original Size: \", new_float_tensor)\n",
    "print(\"Size after view method\", twoD_float_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You get the same result as the previous example. The <b>-1</b> can represent any size. However, be careful because you can set only one argument as <b>-1</b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also convert a <b>numpy</b> array to a <b>tensor</b>, for example: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The dtype of new tensor:  torch.float64\n",
      "The type of new tensor:  torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "# Convert a numpy array to a tensor\n",
    "\n",
    "numpy_array = np.array([0.0, 1.0, 2.0, 3.0, 4.0])\n",
    "new_tensor = torch.from_numpy(numpy_array)\n",
    "\n",
    "print(\"The dtype of new tensor: \", new_tensor.dtype)\n",
    "print(\"The type of new tensor: \", new_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Converting a <b>tensor</b> to a <b>numpy</b> is also supported in PyTorch. The syntax is shown below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The numpy array from tensor:  [0. 1. 2. 3. 4.]\n",
      "The dtype of numpy array:  float64\n"
     ]
    }
   ],
   "source": [
    "# Convert a tensor to a numpy array\n",
    "\n",
    "back_to_numpy = new_tensor.numpy()\n",
    "print(\"The numpy array from tensor: \", back_to_numpy)\n",
    "print(\"The dtype of numpy array: \", back_to_numpy.dtype)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<code>back_to_numpy</code> and <code>new_tensor</code> still point to <code>numpy_array</code>. As a result if we change <code>numpy_array</code> both <code>back_to_numpy</code> and <code>new_tensor</code> will change. For example if we set all the elements in <code>numpy_array</code> to zeros, <code>back_to_numpy</code> and <code> new_tensor</code> will follow suit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new tensor points to numpy_array :  tensor([0., 0., 0., 0., 0.], dtype=torch.float64)\n",
      "and back to numpy array points to the tensor:  [0. 0. 0. 0. 0.]\n"
     ]
    }
   ],
   "source": [
    "# Set all elements in numpy array to zero \n",
    "numpy_array[:] = 0\n",
    "print(\"The new tensor points to numpy_array : \", new_tensor)\n",
    "print(\"and back to numpy array points to the tensor: \", back_to_numpy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Pandas Series</b> can also be converted by using the numpy array that is stored in <code>pandas_series.values</code>. Note that <code>pandas_series</code> can be any pandas_series object. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The new tensor from numpy array:  tensor([ 0.1000,  2.0000,  0.3000, 10.1000], dtype=torch.float64)\n",
      "The dtype of new tensor:  torch.float64\n",
      "The type of new tensor:  torch.DoubleTensor\n"
     ]
    }
   ],
   "source": [
    "# Convert a panda series to a tensor\n",
    "\n",
    "pandas_series=pd.Series([0.1, 2, 0.3, 10.1])\n",
    "new_tensor=torch.from_numpy(pandas_series.values)\n",
    "print(\"The new tensor from numpy array: \", new_tensor)\n",
    "print(\"The dtype of new tensor: \", new_tensor.dtype)\n",
    "print(\"The type of new tensor: \", new_tensor.type())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "consider the following tensor "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "this_tensor=torch.tensor([0,1, 2,3]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method <code>item()</code> returns the value of this tensor as a standard Python number. This only works for one element. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the first item is given by 0 the first tensor value is given by  tensor(0)\n",
      "the second item is given by 1 the second tensor value is given by  tensor(1)\n",
      "the third  item is given by 2 the third tensor value is given by  tensor(2)\n"
     ]
    }
   ],
   "source": [
    "this_tensor=torch.tensor([0,1, 2,3]) \n",
    "\n",
    "print(\"the first item is given by\",this_tensor[0].item(),\"the first tensor value is given by \",this_tensor[0])\n",
    "print(\"the second item is given by\",this_tensor[1].item(),\"the second tensor value is given by \",this_tensor[1])\n",
    "print(\"the third  item is given by\",this_tensor[2].item(),\"the third tensor value is given by \",this_tensor[2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we can use the method <code> tolist()</code> to return a list "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor: tensor([0, 1, 2, 3]) \n",
      "list: [0, 1, 2, 3]\n"
     ]
    }
   ],
   "source": [
    "torch_to_list=this_tensor.tolist()\n",
    "\n",
    "print('tensor:', this_tensor,\"\\nlist:\",torch_to_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to convert <code>your_tensor</code> to a 1X5 tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: convert the following tensor to a tensor object with 1 row and 5 columns\n",
    "\n",
    "your_tensor = torch.tensor([1, 2, 3, 4, 5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "<!-- \n",
    "your_new_tensor = your_tensor.view(1, 5)\n",
    "print(\"Original Size: \", your_tensor)\n",
    "print(\"Size after view method\", your_new_tensor)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Index_Slice\">Indexing and Slicing</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In Python, <b>the index starts with 0</b>. Therefore, the last index will always be 1 less than the length of the tensor object.\n",
    "You can access the value on a certain index by using the square bracket, for example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The value on index 0: tensor(0)\n",
      "The value on index 1: tensor(1)\n",
      "The value on index 2: tensor(2)\n",
      "The value on index 3: tensor(3)\n",
      "The value on index 4: tensor(4)\n"
     ]
    }
   ],
   "source": [
    "# A tensor for showing how the indexs work on tensors\n",
    "\n",
    "index_tensor = torch.tensor([0, 1, 2, 3, 4])\n",
    "print(\"The value on index 0:\",index_tensor[0])\n",
    "print(\"The value on index 1:\",index_tensor[1])\n",
    "print(\"The value on index 2:\",index_tensor[2])\n",
    "print(\"The value on index 3:\",index_tensor[3])\n",
    "print(\"The value on index 4:\",index_tensor[4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note that the <code>index_tensor[5]</code> will create an error.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The index is shown in the following figure: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/idex_1.png\" width=\"500\" alt=\"Python Index\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you'll see how to change the values on certain indexes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Suppose you have a tensor as shown here: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tensor for showing how to change value according to the index\n",
    "\n",
    "tensor_sample = torch.tensor([20, 1, 2, 3, 4])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign the value on index 0 as 100:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital value on index 0: tensor(20)\n",
      "Modified tensor: tensor([100,   1,   2,   3,   4])\n"
     ]
    }
   ],
   "source": [
    "# Change the value on the index 0 to 100\n",
    "\n",
    "print(\"Inital value on index 0:\", tensor_sample[0])\n",
    "tensor_sample[0] = 100\n",
    "print(\"Modified tensor:\", tensor_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the value on index 0 changes. Change the value on index 4 to 0:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital value on index 4: tensor(4)\n",
      "Modified tensor: tensor([100,   1,   2,   3,   0])\n"
     ]
    }
   ],
   "source": [
    "# Change the value on the index 4 to 0\n",
    "\n",
    "print(\"Inital value on index 4:\", tensor_sample[4])\n",
    "tensor_sample[4] = 0\n",
    "print(\"Modified tensor:\", tensor_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The value on index 4 turns to 0."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you are familiar with Python, you know that there is a feature called slicing on a list. Tensors support the same feature. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get the subset of <code>tensor_sample</code>. The subset should contain the values in <code>tensor_sample</code> from index 1 to index 3."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original tensor sample:  tensor([100,   1,   2,   3,   0])\n",
      "The subset of tensor sample: tensor([1, 2, 3])\n"
     ]
    }
   ],
   "source": [
    "# Slice tensor_sample\n",
    "\n",
    "subset_tensor_sample = tensor_sample[1:4]\n",
    "print(\"Original tensor sample: \", tensor_sample)\n",
    "print(\"The subset of tensor sample:\", subset_tensor_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a result, the <code>subset_tensor_sample</code> returned only the values on index 1, index 2, and index 3. Then, it stored them in a <code>subset_tensor_sample</code>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: The number on the left side of the colon represents the index of the first value. The number on the right side of the colon is always 1 larger than the index of the last value. For example, <code>tensor_sample[1:4]</code> means you get values from the index 1 to index 3 <i>(4-1)</i></b>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As for assigning values to the certain index, you can also assign the value to the slices:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Change the value of <code>tensor_sample</code> from index 3 to index 4:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Inital value on index 3 and index 4: tensor([3, 0])\n",
      "Modified tensor: tensor([100,   1,   2, 300, 400])\n"
     ]
    }
   ],
   "source": [
    "# Change the values on index 3 and index 4\n",
    "\n",
    "print(\"Inital value on index 3 and index 4:\", tensor_sample[3:5])\n",
    "tensor_sample[3:5] = torch.tensor([300.0, 400.0])\n",
    "print(\"Modified tensor:\", tensor_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values on both index 3 and index 4 were changed. The values on other indexes remain the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also use a variable to contain the selected indexes and pass that variable to a tensor slice operation as a parameter, for example:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inital tensor_sample tensor([100,   1,   2, 300, 400])\n",
      "The subset of tensor_sample with the values on index 3 and 4:  tensor([300, 400])\n"
     ]
    }
   ],
   "source": [
    "# Using variable to contain the selected index, and pass it to slice operation\n",
    "\n",
    "selected_indexes = [3, 4]\n",
    "subset_tensor_sample = tensor_sample[selected_indexes]\n",
    "print(\"The inital tensor_sample\", tensor_sample)\n",
    "print(\"The subset of tensor_sample with the values on index 3 and 4: \", subset_tensor_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also assign one value to the selected indexes by using the variable. For example, assign 100,000 to all the <code>selected_indexes</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The inital tensor_sample tensor([100,   1,   2, 300, 400])\n",
      "Modified tensor with one value:  tensor([   100, 100000,      2, 100000,    400])\n"
     ]
    }
   ],
   "source": [
    "#Using variable to assign the value to the selected indexes\n",
    "\n",
    "print(\"The inital tensor_sample\", tensor_sample)\n",
    "selected_indexes = [1, 3]\n",
    "tensor_sample[selected_indexes] = 100000\n",
    "print(\"Modified tensor with one value: \", tensor_sample)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The values on index 1 and index 3 were changed to 100,000. Others remain the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: You can use only one value for the assignment.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Try to change the values on index 3, 4, 7 of the following tensor to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Change the values on index 3, 4, 7 to 0\n",
    "\n",
    "practice_tensor = torch.tensor([2, 7, 3, 4, 6, 2, 3, 1, 2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "<!-- \n",
    "selected_indexes = [3, 4, 7]\n",
    "practice_tensor[selected_indexes] = 0\n",
    "print(\"New Practice Tensor: \", practice_tensor)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Tensor_Func\">Tensor Functions</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this section, you'll work with some methods that you can apply to tensor objects."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Mean and Standard Deviation</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You'll review the mean and standard deviation methods first. They are two basic statistical methods."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor with values <i>[1.0, -1, 1, -1]</i>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor example:  tensor([ 1., -1.,  1., -1.])\n"
     ]
    }
   ],
   "source": [
    "# Sample tensor for mathmatic calculation methods on tensor\n",
    "\n",
    "math_tensor = torch.tensor([1.0, -1.0, 1, -1])\n",
    "print(\"Tensor example: \", math_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the mean method:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The mean of math_tensor:  tensor(0.)\n"
     ]
    }
   ],
   "source": [
    "#Calculate the mean for math_tensor\n",
    "\n",
    "mean = math_tensor.mean()\n",
    "print(\"The mean of math_tensor: \", mean)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The standard deviation can also be calculated by using <code><i>tensor_obj</i>.std()</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The standard deviation of math_tensor:  tensor(1.1547)\n"
     ]
    }
   ],
   "source": [
    "#Calculate the standard deviation for math_tensor\n",
    "\n",
    "standard_deviation = math_tensor.std()\n",
    "print(\"The standard deviation of math_tensor: \", standard_deviation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Max and Min</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you'll review another two useful methods: <code><i>tensor_obj</i>.max()</code> and <code><i>tensor_obj</i>.min()</code>. These two methods are used for finding the maximum value and the minimum value in the tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a <code>max_min_tensor</code>: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor example:  tensor([1, 1, 3, 5, 5])\n"
     ]
    }
   ],
   "source": [
    "# Sample for introducing max and min methods\n",
    "\n",
    "max_min_tensor = torch.tensor([1, 1, 3, 5, 5])\n",
    "print(\"Tensor example: \", max_min_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note: There are two minimum numbers as 1 and two maximum numbers as 5 in the tensor. Can you guess how PyTorch is going to deal with the duplicates?</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Apply <code><i>tensor_obj</i>.max()</code> on <code>max_min_tensor</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum number in the tensor:  tensor(5)\n"
     ]
    }
   ],
   "source": [
    "# Method for finding the maximum value in the tensor\n",
    "\n",
    "max_val = max_min_tensor.max()\n",
    "print(\"Maximum number in the tensor: \", max_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is <code>tensor(5)</code>. Therefore, the method <code><i>tensor_obj</i>.max()</code> is grabbing the maximum value but not the elements that contain the maximum value in the tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    " max_min_tensor.max()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use <code><i>tensor_obj</i>.min()</code> on <code>max_min_tensor</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Minimum number in the tensor:  tensor(1)\n"
     ]
    }
   ],
   "source": [
    "# Method for finding the minimum value in the tensor\n",
    "\n",
    "min_val = max_min_tensor.min()\n",
    "print(\"Minimum number in the tensor: \", min_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The answer is <code>tensor(1)</code>. Therefore, the method <code><i>tensor_obj</i>.min()</code> is grabbing the minimum value but not the elements that contain the minimum value in the tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Sin</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sin is the trigonometric function of an angle. Again, you will not be introducedvto any mathematic functions. You'll focus on Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor with 0, π/2 and π. Then, apply the sin function on the tensor. Notice here that the <code>sin()</code> is not a method of tensor object but is a function of torch:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The sin result of pi_tensor:  tensor([ 0.0000e+00,  1.0000e+00, -8.7423e-08])\n"
     ]
    }
   ],
   "source": [
    "# Method for calculating the sin result of each element in the tensor\n",
    "\n",
    "pi_tensor = torch.tensor([0, np.pi/2, np.pi])\n",
    "sin = torch.sin(pi_tensor)\n",
    "print(\"The sin result of pi_tensor: \", sin)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resultant tensor <code>sin</code> contains the result of the <code>sin</code> function applied to each element in the <code>pi_tensor</code>.<br>\n",
    "This is different from the previous methods. For <code><i>tensor_obj</i>.mean()</code>, <code><i>tensor_obj</i>.std()</code>, <code><i>tensor_obj</i>.max()</code>, and <code><i>tensor_obj</i>.min()</code>, the result is a tensor with only one number because these are aggregate methods.<br>\n",
    "However, the <code>torch.sin()</code> is not. Therefore, the resultant tensors have the same length as the input tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Create Tensor by <code>torch.linspace()</code></h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A useful function for plotting mathematical functions is <code>torch.linspace()</code>. <code>torch.linspace()</code> returns evenly spaced numbers over a specified interval. You specify the starting point of the sequence and the ending point of the sequence. The parameter <code>steps</code> indicates the number of samples to generate. Now, you'll work with <code>steps = 5</code>."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First Try on linspace tensor([-2., -1.,  0.,  1.,  2.])\n"
     ]
    }
   ],
   "source": [
    "# First try on using linspace to create tensor\n",
    "\n",
    "len_5_tensor = torch.linspace(-2, 2, steps = 5)\n",
    "print (\"First Try on linspace\", len_5_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assign <code>steps</code> with 9:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Second Try on linspace tensor([-2.0000, -1.5000, -1.0000, -0.5000,  0.0000,  0.5000,  1.0000,  1.5000,\n",
      "         2.0000])\n"
     ]
    }
   ],
   "source": [
    "# Second try on using linspace to create tensor\n",
    "\n",
    "len_9_tensor = torch.linspace(-2, 2, steps = 9)\n",
    "print (\"Second Try on linspace\", len_9_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use both <code>torch.linspace()</code> and <code>torch.sin()</code> to construct a tensor that contains the 100 sin result in range from 0 (0 degree) to 2π (360 degree): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the tensor within 0 to 360 degree\n",
    "\n",
    "pi_tensor = torch.linspace(0, 2*np.pi, 100)\n",
    "sin_result = torch.sin(pi_tensor)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the result to get a clearer picture. You must cast the tensor to a numpy array before plotting it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x1252bb110>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot sin_result\n",
    "\n",
    "plt.plot(pi_tensor.numpy(), sin_result.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you know the trigonometric function, you will notice this is the diagram of the sin result in the range 0 to 360 degrees."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Construct a tensor with 25 steps in the range 0 to π/2. Print out the Maximum and Minimum number. Also, plot  a graph showing the diagram that shows the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: Create your tensor, print max and min number, plot the sin result diagram\n",
    "\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "<!-- \n",
    "pi_tensor = torch.linspace(0, np.pi/2, 100)\n",
    "print(\"Max Number: \", pi_tensor.max())\n",
    "print(\"Min Number\", pi_tensor.min())\n",
    "sin_result = torch.sin(pi_tensor)\n",
    "plt.plot(pi_tensor.numpy(), sin_result.numpy())\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2 id=\"Tensor_Op\">Tensor Operations</h2>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the following section, you'll work with operations that you can apply to a tensor."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tensor Addition</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can perform addition between two tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor <code>u</code> with 1 dimension and 2 elements. Then, create another tensor <code>v</code> with the same number of dimensions and the same number of elements:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create two sample tensors\n",
    "\n",
    "u = torch.tensor([1, 0])\n",
    "v = torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add <code>u</code> and <code>v</code> together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result tensor:  tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# Add u and v\n",
    "\n",
    "w = u + v\n",
    "print(\"The result tensor: \", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is <code>tensor([1, 1])</code>. The behavior is <i>[1 + 0, 0 + 1]</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the result to to get a clearer picture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot u, v, w\n",
    "\n",
    "plotVec([\n",
    "    {\"vector\": u.numpy(), \"name\": 'u', \"color\": 'r'},\n",
    "    {\"vector\": v.numpy(), \"name\": 'v', \"color\": 'b'},\n",
    "    {\"vector\": w.numpy(), \"name\": 'w', \"color\": 'g'}\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Try</h3> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implement the tensor subtraction with <code>u</code> and <code>v</code> as u-v."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try by yourself to get a result of u-v\n",
    "\n",
    "u = torch.tensor([1, 0])\n",
    "v = torch.tensor([0, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "<!--\n",
    "print(\"The result tensor: \", u-v)\n",
    "-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tensors must be of the same data type to perform addition as well as other operations.If you uncomment the  following code and try to run it you will get an error as the two tensors are of two different data types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.tensor([1,2,3],dtype=torch.int64)+torch.tensor([1,2,3],dtype=torch.float6464)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can add a scalar to the tensor. Use <code>u</code> as the sample tensor:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Addition Result:  tensor([2, 3, 4, 0])\n"
     ]
    }
   ],
   "source": [
    "# tensor + scalar\n",
    "\n",
    "u = torch.tensor([1, 2, 3, -1])\n",
    "v = u + 1\n",
    "print (\"Addition Result: \", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is simply adding 1 to each element in tensor <code>u</code> as shown in the following image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src = \"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/chapter%201/brodcasting.gif\" width = \"500\" alt=\"tensor addition\" />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Tensor Multiplication </h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, you'll review the multiplication between a tensor and a scalar."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a tensor with value <code>[1, 2]</code> and then multiply it by 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of 2 * u:  tensor([2, 4])\n"
     ]
    }
   ],
   "source": [
    "# tensor * scalar\n",
    "\n",
    "u = torch.tensor([1, 2])\n",
    "v = 2 * u\n",
    "print(\"The result of 2 * u: \", v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is <code>tensor([2, 4])</code>, so the code <code>2 * u</code> multiplies each element in the tensor by 2. This is how you get the product between a vector or matrix and a scalar in linear algebra."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use multiplication between two tensors."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create two tensors <code>u</code> and <code>v</code> and then multiply them together:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The result of u * v tensor([3, 4])\n"
     ]
    }
   ],
   "source": [
    "# tensor * tensor\n",
    "\n",
    "u = torch.tensor([1, 2])\n",
    "v = torch.tensor([3, 2])\n",
    "w = u * v\n",
    "print (\"The result of u * v\", w)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is simply <code>tensor([3, 4])</code>. This result is achieved by multiplying every element in <code>u</code> with the corresponding element in the same position <code>v</code>, which is similar to <i>[1 * 3, 2 * 2]</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Dot Product</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dot product is a special operation for a vector that you can use in Torch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is the dot product of the two tensors <code>u</code> and <code>v</code>:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dot Product of u, v: tensor(7)\n"
     ]
    }
   ],
   "source": [
    "# Calculate dot product of u, v\n",
    "\n",
    "u = torch.tensor([1, 2])\n",
    "v = torch.tensor([3, 2])\n",
    "\n",
    "print(\"Dot Product of u, v:\", torch.dot(u,v))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The result is <code>tensor(7)</code>. The function is <i>1 x 3 + 2 x 2 = 7</i>."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Practice</h3>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the list <i>[-1, 1]</i> and <i>[1, 1]</i> to tensors <code>u</code> and <code>v</code>. Then, plot the tensor <code>u</code> and <code>v</code> as a vector by using the function <code>plotVec</code> and find the dot product:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Practice: calculate the dot product of u and v, and plot out two vectors\n",
    "\n",
    "# Type your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Double-click <b>here</b> for the solution.\n",
    "<!-- \n",
    "u= torch.tensor([-1, 1])\n",
    "v= torch.tensor([1, 1])\n",
    "plotVec([\n",
    "    {\"vector\": u.numpy(), \"name\": 'u', \"color\": 'r'},\n",
    "    {\"vector\": v.numpy(), \"name\": 'v', \"color\": 'b'}\n",
    "])\n",
    "print(\"The Dot Product is\",np.dot(u, v))\n",
    " -->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--Empty Space for separating topics-->"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See <a href=\"https://docs.scipy.org/doc/numpy-1.13.0/user/basics.broadcasting.html\">Broadcasting</a> for more information on numpy that is similar to PyTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a href=\"http://cocl.us/pytorch_link_bottom\">\n",
    "    <img src=\"https://s3-api.us-geo.objectstorage.softlayer.net/cf-courses-data/CognitiveClass/DL0110EN/notebook_images%20/notebook_bottom%20.png\" width=\"750\" alt=\"PyTorch Bottom\" />\n",
    "</a>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>About the Authors:</h2> \n",
    "\n",
    "<a href=\"https://www.linkedin.com/in/joseph-s-50398b136/\">Joseph Santarcangelo</a> has a PhD in Electrical Engineering, his research focused on using machine learning, signal processing, and computer vision to determine how videos impact human cognition. Joseph has been working for IBM since he completed his PhD."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other contributors: <a href=\"https://www.linkedin.com/in/michelleccarey/\">Michelle Carey</a>, <a href=\"www.linkedin.com/in/jiahui-mavis-zhou-a4537814a\">Mavis Zhou</a> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Copyright &copy; 2018 <a href=\"cognitiveclass.ai?utm_source=bducopyrightlink&utm_medium=dswb&utm_campaign=bdu\">cognitiveclass.ai</a>. This notebook and its source code are released under the terms of the <a href=\"https://bigdatauniversity.com/mit-license/\">MIT License</a>."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
